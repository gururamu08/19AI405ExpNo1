{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbbf181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "class Thing: \n",
    "    \"\"\"\n",
    "    This represents any physical object that can appear in an Environment. \"\"\"\n",
    "\n",
    "    def is_alive(self):\n",
    "        \"\"\"Things that are 'alive' should return true.\"\"\"\n",
    "        return hasattr(self, \"alive\") and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Display the agent's internal state. Subclasses should override.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "068fa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(Thing):\n",
    "    \n",
    "    \"\"\"\n",
    "        An Agent is a subclass of Thing \"\"\"\n",
    "\n",
    "    def __init__(self, program=None):\n",
    "        self.alive = True\n",
    "        self.performance = 0 \n",
    "        self.program = program\n",
    "\n",
    "    def can_grab(self, thing):\n",
    "        \"\"\"Return True if this agent can grab this thing. Override for appropriate subclasses of Agent and Thing.\"\"\" \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f0bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableDrivenAgentProgram(table): \n",
    "    \"\"\"\n",
    "    [Figure 2.7]\n",
    "    This agent selects an action based on the percept sequence. It is practical only for tiny domains.\n",
    "    To customize it, provide as table a dictionary of all\n",
    "    {percept_sequence:action} pairs. \"\"\"\n",
    "    percepts = []\n",
    "    \n",
    "    def program(percept):\n",
    "        action = None\n",
    "        percepts.append(percept)\n",
    "        action = table.get(tuple(percepts))\n",
    "        return action \n",
    "    return program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36f34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_A, room_B = (0, 0), (1, 0)  # The two locations for the vacuum cleaner to clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a5e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableDrivenVacuumAgent():\n",
    "    \"\"\"\n",
    "    Tabular approach towards cleaning environment. \n",
    "    \"\"\"\n",
    "        \n",
    "    table = {\n",
    "        ((room_A, \"Dirty\"),): \"Suck\",\n",
    "        ((room_A, \"Clean\"),): \"Right\",\n",
    "        ((room_B, \"Dirty\"),): \"Suck\",\n",
    "        ((room_B, \"Clean\"),): \"Left\",\n",
    "    }\n",
    "    return Agent(TableDrivenAgentProgram(table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43f8c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Agent at 0x224e5eeb110>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TableDrivenVacuumAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09662dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Abstract class representing an Environment. 'Real' Environment classes inherit from this. Your Environment will typically need to implement:\n",
    "    percept:\tDefine the percept that an agent sees. execute_action:\tDefine the effects of executing an action.\n",
    "    Also update the agent.performance slot.\n",
    "    The environment keeps a list of .things and .agents (which is a subset of .things). Each agent has a .performance slot, initialized to 0.\n",
    "    Each thing has a .location slot, even though some environments may not need this.\"\"\"\n",
    "\n",
    "    def _init_(self):\n",
    "        self.things = [] \n",
    "        self.agents = []\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Return the percept that the agent sees at this point. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change the world to reflect this action. (Implement this.)\"\"\" \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Default location to place a new thing with unspecified location.\"\"\"\n",
    "        return None\n",
    "    def is_done(self):\n",
    "        \"\"\"By default, we're done when we can't find a live agent.\"\"\" \n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will do. If there are interactions between them, you'll need to override this method.\"\"\"\n",
    "        if not self.is_done(): \n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent))) \n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions): \n",
    "                self.execute_action(agent, action)\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return \n",
    "            self.step()\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For convenience, if thing is an agent program we make a new agent for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        if thing in self.things:\n",
    "            print(\"Can't add the same thing twice\") \n",
    "        else:\n",
    "            thing.location = (location if location is not None else self.default_location(thing))\n",
    "            self.things.append(thing) \n",
    "            if isinstance(thing, Agent):\n",
    "                thing.performance = 0 \n",
    "                self.agents.append(thing)\n",
    "\n",
    "    def delete_thing(self, thing):\n",
    "        \"\"\"Remove a thing from the environment.\"\"\"\n",
    "        try:\n",
    "            self.things.remove(thing) \n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\" in Environment delete_thing\")\n",
    "            print(\" Thing to be removed: {} at {}\".format(thing, thing.location))\n",
    "            print(\" from list: {}\".format([(thing, thing.location) for thing in self.things]))\n",
    "        if thing in self.agents: \n",
    "            self.agents.remove(thing)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f47933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ec19095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVacuumEnvironment(Environment):\n",
    "    \"\"\"This environment has two locations, A and B. Each can be clean or dirty. The agent perceives its location and the location's status. This serves as an example of how to implement a simple Environment for a vacuum cleaner agent.\"\"\"\n",
    "\n",
    "    def _init_(self):\n",
    "        super()._init_()\n",
    "        self.status = {room_A: random.choice([\"Clean\", \"Dirty\"]), room_B: random.choice([\"Clean\", \"Dirty\"]),}\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return [TableDrivenVacuumAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Clean/Dirty).\"\"\"\n",
    "        return agent.location, self.status[agent.location]\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status; track performance. Score +10 for each clean action.\"\"\"\n",
    "        if action == \"Right\":\n",
    "            agent.location = room_B\n",
    "            agent.performance -= 1\n",
    "        elif action == \"Left\":\n",
    "            agent.location = room_A\n",
    "            agent.performance -= 1\n",
    "        elif action == \"Suck\":\n",
    "            self.status[agent.location] = \"Clean\"\n",
    "            agent.performance += 10\n",
    "    def default_location(self, thing):\n",
    "        return random.choice([room_A, room_B])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "028ac735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Abstract class representing an Environment. 'Real' Environment classes inherit from this. Your Environment will typically need to implement:\n",
    "    percept:\tDefine the percept that an agent sees. execute_action:\tDefine the effects of executing an action.\n",
    "    Also update the agent.performance slot.\n",
    "    The environment keeps a list of .things and .agents (which is a subset of .things). Each agent has a .performance slot, initialized to 0.\n",
    "    Each thing has a .location slot, even though some environments may not need this.\"\"\"\n",
    "\n",
    "    def _init_(self):\n",
    "        self.things = [] \n",
    "        self.agents = []\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Return the percept that the agent sees at this point. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change the world to reflect this action. (Implement this.)\"\"\" \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Default location to place a new thing with unspecified location.\"\"\"\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a39a340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_name_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_name_\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_main_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     agent \u001b[38;5;241m=\u001b[39m TableDrivenVacuumAgent()\n\u001b[0;32m      3\u001b[0m     environment \u001b[38;5;241m=\u001b[39m SimpleVacuumEnvironment()\n",
      "\u001b[1;31mNameError\u001b[0m: name '_name_' is not defined"
     ]
    }
   ],
   "source": [
    "if _name_ == \"_main_\":\n",
    "    agent = TableDrivenVacuumAgent()\n",
    "    environment = SimpleVacuumEnvironment()\n",
    "    environment.add_thing(agent)\n",
    "    \n",
    "    print(\"\\tStatus of rooms before cleaning\")\n",
    "    print(environment.status)\n",
    "    print(\"AgentLocation : {0}\".format(agent.location)) \n",
    "    print(\"Performance : {0}\".format(agent.performance))\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    for i in range(2):\n",
    "        environment.run(steps=1)\n",
    "        print(\"\\n\\tStatus of rooms after cleaning\") \n",
    "        print(environment.status)\n",
    "        print(\"AgentLocation : {0}\".format(agent.location)) \n",
    "        print(\"Performance : {0}\".format(agent.performance)) \n",
    "    time.sleep(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
